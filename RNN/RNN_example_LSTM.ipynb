{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Example\n",
    "Let's keep the example simple since our main foucs is on understanding the APIs. \n",
    "\n",
    "The data we'll be using is part of a dataset taken [here](https://www.kaggle.com/datasets/dgawlik/nyse) from Kaggle. This is a time-series data (ordered by time) of Yahoo's highest stock prices per day **(?)**. Our objective is as follows:\n",
    "\"Given the price of the previous 5 days, predict the price on the next (6th) day\"\n",
    "\n",
    "The data has already been cleaned and made ready to be fed into the model.\n",
    "To be more specific, the $ i^{th} $ training sample, denoted as $ (X^{i}, y^{i}) $, is such that $ X^{i} $ consists of some 5 consecutive days' of prices and $ y^{i} $ denotes the price on the 6th day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1757, 5, 1)\n",
      "Shape of y: (1757, 1)\n"
     ]
    }
   ],
   "source": [
    "import data.data_extraction as data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X, y = data.get_data(\".\\data\\prices-split-adjusted.csv\")\n",
    "print(\"Shape of X: {}\".format(X.shape))\n",
    "print(\"Shape of y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X`, which is going to serve as the input to our final *model*, is of shape `[batch, timestamp, feature]`:\n",
    "-   `batch` refers to the total number of samples to our model\n",
    "-   `timestamp` refers to the length of each time-series sample (5 in our case)\n",
    "-   `feature` refers to the number of features in each timestamp of the sample (which is just 1 in this case - the highest stock value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a closer look at the training sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 3, T = 5\n",
      "+--------+--------+-------+---------+\n",
      "| Sample | Inputs         | Outputs |\n",
      "+        +--------+-------+---------+\n",
      "|        | Day    | Price | Price   |\n",
      "+--------+--------+-------+---------+\n",
      "| 1      | Day_1  | 17.2  | 16.83   |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_2  | 17.23 |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_3  | 17.3  |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_4  | 16.9  |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_5  | 16.76 |         |\n",
      "+--------+--------+-------+---------+\n",
      "| 2      | Day_1  | 17.23 | 16.86   |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_2  | 17.3  |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_3  | 16.9  |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_4  | 16.76 |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_5  | 16.83 |         |\n",
      "+--------+--------+-------+---------+\n",
      "| 3      | Day_1  | 17.3  | 16.98   |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_2  | 16.9  |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_3  | 16.76 |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_4  | 16.83 |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_5  | 16.86 |         |\n",
      "+--------+--------+-------+---------+\n"
     ]
    }
   ],
   "source": [
    "data.display_samples(X[0:3], y[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Train!\n",
    "We'll use the `Sequential API` to build and train our RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1229, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_inputs = 1  # number of features\n",
    "n_neurons = 25\n",
    "n_outputs = 1\n",
    "n_layers = 2\n",
    "batch_size = 32\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "39/39 [==============================] - 2s 12ms/step - loss: 934.0297 - val_loss: 848.4723\n",
      "Epoch 2/25\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 830.0425 - val_loss: 745.9431\n",
      "Epoch 3/25\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 723.4783 - val_loss: 648.7867\n",
      "Epoch 4/25\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 648.5870 - val_loss: 591.6568\n",
      "Epoch 5/25\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 592.2472 - val_loss: 547.3132\n",
      "Epoch 6/25\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 552.1758 - val_loss: 510.4150\n",
      "Epoch 7/25\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 515.6868 - val_loss: 476.3981\n",
      "Epoch 8/25\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 481.9489 - val_loss: 445.2462\n",
      "Epoch 9/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 450.6854 - val_loss: 416.1951\n",
      "Epoch 10/25\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 421.6995 - val_loss: 389.2437\n",
      "Epoch 11/25\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 394.5829 - val_loss: 364.4434\n",
      "Epoch 12/25\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 369.6638 - val_loss: 341.2488\n",
      "Epoch 13/25\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 346.5727 - val_loss: 320.1664\n",
      "Epoch 14/25\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 325.2373 - val_loss: 300.8604\n",
      "Epoch 15/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 305.7550 - val_loss: 282.7538\n",
      "Epoch 16/25\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 287.6750 - val_loss: 266.4843\n",
      "Epoch 17/25\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 271.1744 - val_loss: 251.6563\n",
      "Epoch 18/25\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 256.0691 - val_loss: 238.1610\n",
      "Epoch 19/25\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 241.9457 - val_loss: 224.2042\n",
      "Epoch 20/25\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 227.5655 - val_loss: 211.2080\n",
      "Epoch 21/25\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 214.1332 - val_loss: 198.6254\n",
      "Epoch 22/25\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 201.0780 - val_loss: 186.5315\n",
      "Epoch 23/25\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 188.7927 - val_loss: 175.3297\n",
      "Epoch 24/25\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 177.2894 - val_loss: 164.5814\n",
      "Epoch 25/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 166.2538 - val_loss: 154.5195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f0b09a7100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RNNcells = [tf.keras.layers.SimpleRNNCell(n_neurons) for _ in range(n_layers)]\n",
    "# rnn = tf.keras.layers.StackedRNNCells(RNNcells, input_shape = (5, n_inputs))\n",
    "# rnn = tf.keras.layers.SimpleRNNCell(n_neurons)\n",
    "rnn = tf.keras.layers.SimpleRNN(n_neurons)\n",
    "RNNmodel = Sequential()\n",
    "# RNNmodel.add(layers.RNN(\n",
    "#     [\n",
    "#         tf.keras.layers.SimpleRNNCell(n_neurons),\n",
    "#         tf.keras.layers.LSTMCell(n_neurons)\n",
    "#     ]\n",
    "# ))\n",
    "RNNmodel.add(rnn)\n",
    "# RNNmodel.add(layers.Dense(64, activation='relu'))\n",
    "RNNmodel.add(layers.Dense(n_outputs, activation='linear'))\n",
    "\n",
    "RNNmodel.compile(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")\n",
    "\n",
    "RNNmodel.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test), \n",
    "    batch_size=batch_size, \n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ans = RNNmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.783026], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ans[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.91], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = tf.keras.layers.LSTM(4, activation='linear', input_shape=(None, 8), return_sequences=True)\n",
    "output_lstm = lstm(inputs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ = lstm.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.engine import keras_tensor\n",
    "isinstance(inputs, keras_tensor.KerasTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.rnn.rnn_utils import standardize_args\n",
    "\n",
    "standardize_args(inputs, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.15028077  0.02378442 -0.15648831 -0.18393101]\n",
      " [ 0.21888971 -0.06897657 -0.5439828  -0.26890522]], shape=(2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(output_lstm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, f, o, c = tf.split(weights_[0], 4, axis=1)\n",
    "i_, f_, o_, c_ = tf.split(weights_[1], 4, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_0 = np.zeros(shape=(4,), dtype=np.float32)\n",
    "i_1 = np.matmul(inputs[0][0], i) + np.matmul(h_0, i_)\n",
    "f_1 = np.matmul(inputs[0][0], f) + np.matmul(h_0, f_)\n",
    "o_1 = np.matmul(inputs[0][0], o) + np.matmul(h_0, o_)\n",
    "c_t = np.matmul(inputs[0][0], c) + np.matmul(h_0, c_)\n",
    "c_1 = i_1 * c_t\n",
    "# h_1 = c_1 * o_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0291979e-02, -4.7132911e-04,  2.0280483e-03,  6.0263123e-05],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_1 * o_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTM' object has no attribute 'initial_states'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m lstm\u001b[39m.\u001b[39;49minitial_states\n",
      "\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LSTM' object has no attribute 'initial_states'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
