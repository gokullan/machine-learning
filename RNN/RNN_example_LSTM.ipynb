{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Example\n",
    "Let's keep the example simple since our main foucs is on understanding the APIs. \n",
    "\n",
    "The data we'll be using is part of a dataset taken [here](https://www.kaggle.com/datasets/dgawlik/nyse) from Kaggle. This is a time-series data (ordered by time) of Yahoo's highest stock prices per day **(?)**. Our objective is as follows:\n",
    "\"Given the price of the previous 5 days, predict the price on the next (6th) day\"\n",
    "\n",
    "The data has already been cleaned and made ready to be fed into the model.\n",
    "To be more specific, the $ i^{th} $ training sample, denoted as $ (X^{i}, y^{i}) $, is such that $ X^{i} $ consists of some 5 consecutive days' of prices and $ y^{i} $ denotes the price on the 6th day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1757, 5, 1)\n",
      "Shape of y: (1757, 1)\n"
     ]
    }
   ],
   "source": [
    "import data.data_extraction as data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X, y = data.get_data(\".\\data\\prices-split-adjusted.csv\")\n",
    "print(\"Shape of X: {}\".format(X.shape))\n",
    "print(\"Shape of y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X`, which is going to serve as the input to our final *model*, is of shape `[batch, timestamp, feature]`:\n",
    "-   `batch` refers to the total number of samples to our model\n",
    "-   `timestamp` refers to the length of each time-series sample (5 in our case)\n",
    "-   `feature` refers to the number of features in each timestamp of the sample (which is just 1 in this case - the highest stock value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a closer look at the training sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 3, T = 5\n",
      "+--------+--------+-------+---------+\n",
      "| Sample | Inputs         | Outputs |\n",
      "+        +--------+-------+---------+\n",
      "|        | Day    | Price | Price   |\n",
      "+--------+--------+-------+---------+\n",
      "| 1      | Day_1  | 17.2  | 16.83   |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_2  | 17.23 |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_3  | 17.3  |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_4  | 16.9  |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_5  | 16.76 |         |\n",
      "+--------+--------+-------+---------+\n",
      "| 2      | Day_1  | 17.23 | 16.86   |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_2  | 17.3  |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_3  | 16.9  |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_4  | 16.76 |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_5  | 16.83 |         |\n",
      "+--------+--------+-------+---------+\n",
      "| 3      | Day_1  | 17.3  | 16.98   |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_2  | 16.9  |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_3  | 16.76 |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_4  | 16.83 |         |\n",
      "+        +--------+-------+         +\n",
      "|        | Day_5  | 16.86 |         |\n",
      "+--------+--------+-------+---------+\n"
     ]
    }
   ],
   "source": [
    "data.display_samples(X[0:3], y[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Train!\n",
    "We'll use the `Sequential API` to build and train our RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1229, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_inputs = 1  # number of features\n",
    "n_neurons = 25\n",
    "n_outputs = 1\n",
    "n_layers = 2\n",
    "batch_size = 32\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "39/39 [==============================] - 3s 21ms/step - loss: 888.1685 - val_loss: 816.7823\n",
      "Epoch 2/25\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 797.4676 - val_loss: 751.3549\n",
      "Epoch 3/25\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 707.8855 - val_loss: 624.2955\n",
      "Epoch 4/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 604.1218 - val_loss: 555.8630\n",
      "Epoch 5/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 518.2236 - val_loss: 454.6849\n",
      "Epoch 6/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 433.9761 - val_loss: 394.6521\n",
      "Epoch 7/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 386.9225 - val_loss: 357.6775\n",
      "Epoch 8/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 352.9790 - val_loss: 326.6665\n",
      "Epoch 9/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 324.2498 - val_loss: 300.4897\n",
      "Epoch 10/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 299.5553 - val_loss: 277.5952\n",
      "Epoch 11/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 278.0466 - val_loss: 257.4103\n",
      "Epoch 12/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 258.8752 - val_loss: 239.9719\n",
      "Epoch 13/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 242.1239 - val_loss: 224.2919\n",
      "Epoch 14/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 227.2638 - val_loss: 210.3025\n",
      "Epoch 15/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 214.2206 - val_loss: 198.1017\n",
      "Epoch 16/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 202.6536 - val_loss: 187.6174\n",
      "Epoch 17/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 192.2894 - val_loss: 177.5563\n",
      "Epoch 18/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 181.9205 - val_loss: 164.8816\n",
      "Epoch 19/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 165.4806 - val_loss: 149.6225\n",
      "Epoch 20/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 152.5461 - val_loss: 137.6276\n",
      "Epoch 21/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 140.3868 - val_loss: 126.6432\n",
      "Epoch 22/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 129.7065 - val_loss: 116.5150\n",
      "Epoch 23/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 119.8223 - val_loss: 107.2409\n",
      "Epoch 24/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 110.6707 - val_loss: 98.8182\n",
      "Epoch 25/25\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 102.3333 - val_loss: 91.0022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd08b0d540>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNNmodel = Sequential()\n",
    "RNNmodel.add(\n",
    "    layers.LSTM(n_neurons)\n",
    ")\n",
    "# RNNmodel.add(\n",
    "#     layers.RNN(\n",
    "#         layers.StackedRNNCells(\n",
    "#             [\n",
    "#                 layers.LSTMCell(n_neurons) for _ in range(n_layers)\n",
    "#             ]\n",
    "#         )\n",
    "#     )\n",
    "# )\n",
    "RNNmodel.add(layers.Dense(n_outputs, activation='linear'))\n",
    "\n",
    "RNNmodel.compile(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")\n",
    "\n",
    "RNNmodel.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test), \n",
    "    batch_size=batch_size, \n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ans = RNNmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [25.036465], Actual: [25.54]\n"
     ]
    }
   ],
   "source": [
    "# compare predicted and actual value\n",
    "idx = 14  # change this to see for a different example\n",
    "print(\"Predicted: {}, Actual: {}\".format(ans[idx], y_test[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = tf.keras.layers.LSTM(4, activation='linear', input_shape=(None, 8), return_sequences=True)\n",
    "output_lstm = lstm(inputs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ = lstm.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.engine import keras_tensor\n",
    "isinstance(inputs, keras_tensor.KerasTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.rnn.rnn_utils import standardize_args\n",
    "\n",
    "standardize_args(inputs, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.15028077  0.02378442 -0.15648831 -0.18393101]\n",
      " [ 0.21888971 -0.06897657 -0.5439828  -0.26890522]], shape=(2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(output_lstm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, f, o, c = tf.split(weights_[0], 4, axis=1)\n",
    "i_, f_, o_, c_ = tf.split(weights_[1], 4, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_0 = np.zeros(shape=(4,), dtype=np.float32)\n",
    "i_1 = np.matmul(inputs[0][0], i) + np.matmul(h_0, i_)\n",
    "f_1 = np.matmul(inputs[0][0], f) + np.matmul(h_0, f_)\n",
    "o_1 = np.matmul(inputs[0][0], o) + np.matmul(h_0, o_)\n",
    "c_t = np.matmul(inputs[0][0], c) + np.matmul(h_0, c_)\n",
    "c_1 = i_1 * c_t\n",
    "# h_1 = c_1 * o_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0291979e-02, -4.7132911e-04,  2.0280483e-03,  6.0263123e-05],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_1 * o_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTM' object has no attribute 'initial_states'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m lstm\u001b[39m.\u001b[39;49minitial_states\n",
      "\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LSTM' object has no attribute 'initial_states'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
